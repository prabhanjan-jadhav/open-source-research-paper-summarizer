{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBR8Dq40aBwLdYQVZheaCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhanjan-jadhav/open-source-research-paper-summarizer/blob/main/Research_paper_summarizer_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and Imports"
      ],
      "metadata": {
        "id": "EfnoS-BTK9Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq langchain openai huggingface_hub arxiv pypdf faiss-cpu tiktoken cohere"
      ],
      "metadata": {
        "id": "mXDMuRa4ultp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR3xOSqarOaU"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "from IPython.display import Markdown\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import HuggingFaceHub, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "# from langchain.embeddings.openai import OpenAIEmbeddings    # credits required\n",
        "# from langchain.embeddings import AlephAlphaAsymmetricSemanticEmbedding   # credits required\n",
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import arxiv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai_api_key = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "3dKBvp5PtlJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ['OPENAI_API_KEY'] = openai_api_key"
      ],
      "metadata": {
        "id": "RdYfZzmwttiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
      ],
      "metadata": {
        "id": "25RCvBELuq0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm(\"hello this is a test\")"
      ],
      "metadata": {
        "id": "QQHXNsWYu9-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't have any OpenAI credits. Therefore, lets find some open source apis."
      ],
      "metadata": {
        "id": "JjsPoh-2xJXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cohere"
      ],
      "metadata": {
        "id": "XCmrjyBxVZb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cohere_api_key = getpass.getpass(\"Cohere API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLwEIVJzVdgD",
        "outputId": "5c61dbb5-d43f-4d05-b90b-c3b86b6f4279"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cohere API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFaceHub"
      ],
      "metadata": {
        "id": "ZP8u485DK5Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_api_key = getpass.getpass(\"HuggingFace API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5aDb__hyikH",
        "outputId": "583bd429-b29a-46b7-9643-4036a3f64d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HuggingFace API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_api_key"
      ],
      "metadata": {
        "id": "Ukq2aLNAypBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hub_llm = HuggingFaceHub(\n",
        "    repo_id =\"OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\",\n",
        "    model_kwargs={'temperature':0.75, 'max_new_tokens':200, 'top_p': 0.95,\n",
        "                  'repetition_penalty': 1.2, 'top_k':50}\n",
        "  )\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "      input_variables = ['question'],\n",
        "      template = '<|prompter|>{question}<|endoftext|><|assistant|>'\n",
        "  )\n",
        "\n",
        "hub_chain = LLMChain(prompt = prompt, llm = hub_llm, verbose=True)"
      ],
      "metadata": {
        "id": "q3P5Tc48vQgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"# Transform the image to the form expected by the model\n",
        "     56 input_image = self.transform.apply_image(image)\n",
        "---> 57 input_image_torch = torch.as_tensor(input_image, device=self.device)\n",
        "     58 input_image_torch = input_image_torch.permute(2, 0, 1).contiguous()[None, :, :, :]\n",
        "     60 self.set_torch_image(input_image_torch, image.shape[:2])\n",
        "\n",
        "RuntimeError: Could not infer dtype of numpy.uint8\"\"\"\n",
        "\n",
        "Markdown(hub_chain.run(text))"
      ],
      "metadata": {
        "id": "y9DSoxOEzDZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's bring in some context."
      ],
      "metadata": {
        "id": "GRo-0PIa7BEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper = next(arxiv.Search(id_list=['2205.11916']).results())\n",
        "\n",
        "Markdown(paper.summary)"
      ],
      "metadata": {
        "id": "3Cwp8DQA7V_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(hub_chain.run(paper.summary))"
      ],
      "metadata": {
        "id": "5aQuwCFR8MZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hub_chain.run(\"give an summary on that\")"
      ],
      "metadata": {
        "id": "lysaMBS_82o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hub_chain.run(\"what is the name of the paper?\")"
      ],
      "metadata": {
        "id": "vRy6s1TpE-xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# See that this is a wrong answer. The api doesn't track your previous prompt for now."
      ],
      "metadata": {
        "id": "A2VE_tEIFdAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the paper searchable"
      ],
      "metadata": {
        "id": "QYMlxrbFF3U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_path = paper.download_pdf()"
      ],
      "metadata": {
        "id": "7PD8LNcXFLUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(paper_path)\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "zTQPt8XCFVak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS49569OGbKZ",
        "outputId": "ec03eee1-02b7-4d69-d1b2-fa09013d517b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\\n\\n\".join([page.page_content for page in pages[:2]])"
      ],
      "metadata": {
        "id": "1p-stJjYGc-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = hub_chain.run(f\"\"\"Pls go through this paper :\n",
        "{content}.\n",
        "\n",
        "\n",
        "Now, based on the content tell me  what is zero shot chain of thought prompting?\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "V27G_FaZIgIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "TX96mGGFKcu7",
        "outputId": "3ec85cc0-b5a8-4095-fe31-b924e49c294c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "It's an AI strategy that relies on human teachers to help kids learn how to write their stories, poems, essays and other creative writing skills. The AI prompts them to make sure they focus on creating stories that best match what your preconceived instructions, and are true/imagined in the story you ask, and it is about."
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find relevant content using embedding search"
      ],
      "metadata": {
        "id": "1-kbNJ_UMSBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "a5maPeRuKnXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = CohereEmbeddings(cohere_api_key=cohere_api_key)\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "pJjnxjnoNjT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = db.similarity_search(\"What is zero-shot chain-of-thought prompting?\")"
      ],
      "metadata": {
        "id": "qQjC5lpzNkpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trb4sLiLWEhl",
        "outputId": "5cb29dfe-1357-4f09-ba62-7ae23873f859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_content = \"\\n\\n\".join([doc.page_content for doc in docs[:1]])"
      ],
      "metadata": {
        "id": "lk_b_0nCbKfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "RJ6OASd_Wizm",
        "outputId": "4bc99cba-232b-485f-a15c-2b637388be8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "language models like PaLM [Chowdhery et al., 2022]. The top row of Figure 1 shows standard\nfew-shot prompting against (few-shot) CoT prompting. Notably, few-shot learning was taken as a\ngiven for tackling such difﬁcult tasks, and the zero-shot baseline performances were not even reported\nin the original work [Wei et al., 2022]. To differentiate it from our method, we call Wei et al. [2022]\nasFew-shot-CoT in this work.\n3 Zero-shot Chain of Thought\nWe propose Zero-shot-CoT, a zero-shot template-based prompting for chain of thought reasoning.\nIt differs from the original chain of thought prompting [Wei et al., 2022] as it does not require\nstep-by-step few-shot examples, and it differs from most of the prior template prompting [Liu et al.,\n2021b] as it is inherently task-agnostic and elicits multi-hop reasoning across a wide range of tasks\nwith a single template. The core idea of our method is simple, as described in Figure 1: add Let’s"
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hub_chain.run(f\"\"\"Acknowledge the below excerpt:\n",
        "{relevant_content}.\n",
        "\n",
        "Based on the above excerpt, what is zero-shot chain-of-thought?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "3GzZhv8-WuSv",
        "outputId": "1e701d55-2681-4d9c-94ed-8d6ea4478f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<|prompter|>Acknowledge the below excerpt:\n",
            "language models like PaLM [Chowdhery et al., 2022]. The top row of Figure 1 shows standard\n",
            "few-shot prompting against (few-shot) CoT prompting. Notably, few-shot learning was taken as a\n",
            "given for tackling such difﬁcult tasks, and the zero-shot baseline performances were not even reported\n",
            "in the original work [Wei et al., 2022]. To differentiate it from our method, we call Wei et al. [2022]\n",
            "asFew-shot-CoT in this work.\n",
            "3 Zero-shot Chain of Thought\n",
            "We propose Zero-shot-CoT, a zero-shot template-based prompting for chain of thought reasoning.\n",
            "It differs from the original chain of thought prompting [Wei et al., 2022] as it does not require\n",
            "step-by-step few-shot examples, and it differs from most of the prior template prompting [Liu et al.,\n",
            "2021b] as it is inherently task-agnostic and elicits multi-hop reasoning across a wide range of tasks\n",
            "with a single template. The core idea of our method is simple, as described in Figure 1: add Let’s.\n",
            "\n",
            "Based on the above excerpt, what is zero-shot chain-of-thought?<|endoftext|><|assistant|>\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zero-Shot COOT stands for \"Chain Of Thought with Out-Of-The-Domain Examples\". In other words, while training the model to solve specific problems, they will learn how to understand text in general terms so that they can apply to any problem given, without needing to go through many steps. It\\'s main benefit is that once trained, you do not have to train it again for every new type of problem you want to try and answer. \\nI hope I answered your question! Is there anything else I should know or explain about COOT?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbgYk-wsaF1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}